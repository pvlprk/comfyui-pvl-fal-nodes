import os
import torch
import numpy as np
import json
from .fal_utils import FalConfig, ImageUtils, ResultProcessor, ApiHandler

class PVL_fal_KontextDevLora_API:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"multiline": True}),
                "image": ("IMAGE",),
                "num_inference_steps": ("INT", {"default": 30, "min": 1, "max": 100}),
                "seed": ("INT", {"default": -1, "min": -1, "max": 4294967295}),
                "guidance_scale": ("FLOAT", {"default": 2.5, "min": 1.0, "max": 20.0, "step": 0.1}),
                "num_images": ("INT", {"default": 1, "min": 1, "max": 4}),
                "output_format": (["jpeg", "png"], {"default": "png"}),
                "sync_mode": ("BOOLEAN", {"default": False}),
                "enable_safety_checker": ("BOOLEAN", {"default": True}),
                "resolution_mode": (["auto", "match_input", "1:1", "16:9", "21:9", "3:2", "2:3", "4:5", "5:4", "3:4", "4:3", "9:16", "9:21"], {"default": "match_input"}),
                "acceleration": (["none", "regular", "high"], {"default": "none"}),
            },
            "optional": {
                "lora_path": ("STRING", {"default": ""}),
                "lora_strength": ("FLOAT", {"default": 1.0, "min": -2.0, "max": 2.0, "step": 0.1}),
                "use_mstudio_proxy": ("BOOLEAN", {"default": False}),
                "Proxy Only if >1K": ("BOOLEAN", {"default": False}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "generate_image"
    CATEGORY = "PVL_tools_FAL"

    def generate_image(self, *args, **kwargs):
        return self.edit_image(*args, **kwargs)

    def _raise(self, msg):
        # Helper to standardize raising: ComfyUI will stop the workflow
        raise RuntimeError(msg)

    def edit_image(self, prompt, image, num_inference_steps, seed, guidance_scale, 
                  num_images, output_format, sync_mode, enable_safety_checker,
                  resolution_mode, acceleration, lora_path="", lora_strength=1.0, **kwargs):
        use_mstudio_proxy, proxy_only_if_gt_1k = ImageUtils.get_proxy_options(kwargs)
        image_url = ImageUtils.image_to_payload_uri(
            image,
            use_mstudio_proxy=use_mstudio_proxy,
            proxy_only_if_gt_1k=proxy_only_if_gt_1k,
        )
        if not image_url:
            self._raise("FAL: failed to upload input image.")

        # Prepare the arguments for the API call
        arguments = {
            "prompt": prompt,
            "image_url": image_url,
            "num_inference_steps": num_inference_steps,
            "guidance_scale": guidance_scale,
            "num_images": num_images,
            "output_format": output_format,
            "sync_mode": sync_mode,
            "enable_safety_checker": enable_safety_checker,
            "resolution_mode": resolution_mode,
            "acceleration": acceleration
        }
        if seed != -1:
            arguments["seed"] = seed
            
        # Add LoRA if path is provided
        if lora_path.strip():
            arguments["loras"] = [{
                "path": lora_path.strip(),
                "scale": lora_strength
            }]

        # Submit the request and get the result (ApiHandler re-raises on failures)
        result = ApiHandler.submit_and_get_result("fal-ai/flux-kontext-lora", arguments)

        # Basic structural validations
        if not isinstance(result, dict):
            self._raise("FAL: unexpected response type (expected dict).")
        if "images" not in result or not result["images"]:
            # Some errors come under an 'error' key; surface that if present
            err_msg = None
            if isinstance(result.get("error"), dict):
                err_msg = result["error"].get("message") or result["error"].get("detail")
            self._raise(f"FAL: no images returned{f' ({err_msg})' if err_msg else ''}.")

        # NSFW detection via official field
        has_nsfw = result.get("has_nsfw_concepts")
        if isinstance(has_nsfw, list) and any(bool(x) for x in has_nsfw):
            self._raise("FAL: NSFW content detected by safety system (has_nsfw_concepts).")

        # Process images (may raise)
        processed_result = ResultProcessor.process_image_result(result)

        # Check for black/empty image(s) and abort
        if processed_result and len(processed_result) > 0:
            img_tensor = processed_result[0]
            if not isinstance(img_tensor, torch.Tensor):
                self._raise("FAL: internal error â€” processed image is not a tensor.")
            # Consider a frame 'black' if all pixels are exactly zero OR mean is extremely low
            if torch.all(img_tensor == 0) or (img_tensor.mean() < 1e-6):
                self._raise("FAL: received an all-black image (likely filtered/failed).")

        return processed_result
